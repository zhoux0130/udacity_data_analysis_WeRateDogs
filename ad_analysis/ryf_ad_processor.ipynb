{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保留易观指数的原始数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "def getDataFromNet():\n",
    "    allInOne = []\n",
    "    for index in range(1,11):\n",
    "        url = 'http://zhishu.analysys.cn/public/qianfan/topRank/listTopRank?page=' + str(index) + '&pageSize=200'\n",
    "        #print(url)\n",
    "        r = requests.get(url)\n",
    "\n",
    "        dataStr = r.text\n",
    "        data = json.loads(dataStr)\n",
    "\n",
    "        data_list = data['datas']['list']\n",
    "        allInOne = allInOne + data_list\n",
    "        \n",
    "    df = json_normalize(allInOne)\n",
    "    #处理初始数据，添加业务关心的数据\n",
    "    df['dayChangeNums'] = df['dayActiveNumsRatio'] * df['dayActiveNums']\n",
    "    df['monthChangeNums'] = df['monthActiveNumsRatio'] * df['monthActiveNums']\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "def write2File(df):\n",
    "    fileName = 'data_20190225.csv'\n",
    "    df.to_csv(fileName, index=False, encoding = 'UTF-8')\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "df = getDataFromNet()\n",
    "write2File(df)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用来处理广告来源数据的分析\n",
    "\n",
    "* 通过url的后缀进行分割，添加一列关键技术点（或者是分享）\n",
    "* 统计文章的时间，来分析用户是博客订阅者，还是通过搜索引擎过来的\n",
    "* 针对访问超过一次的用户，单独进行分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>domain</th>\n",
       "      <th>ref_link</th>\n",
       "      <th>portal_page</th>\n",
       "      <th>keywords</th>\n",
       "      <th>visit_IP</th>\n",
       "      <th>unique_no</th>\n",
       "      <th>total_visit_duration_time</th>\n",
       "      <th>total_visit_page_one_time</th>\n",
       "      <th>...</th>\n",
       "      <th>brewer</th>\n",
       "      <th>lang</th>\n",
       "      <th>screen</th>\n",
       "      <th>screen_color</th>\n",
       "      <th>Flash</th>\n",
       "      <th>has_cookie</th>\n",
       "      <th>has_java</th>\n",
       "      <th>this_time_visit_start</th>\n",
       "      <th>visit_portal_time</th>\n",
       "      <th>portal_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1063.0</td>\n",
       "      <td>2019/02/22 13:42:29</td>\n",
       "      <td>深圳</td>\n",
       "      <td>360搜索</td>\n",
       "      <td>http://www.youkeda.com</td>\n",
       "      <td>--</td>\n",
       "      <td>219.133.66.223</td>\n",
       "      <td>1839110690557959428</td>\n",
       "      <td>14s</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Google Chrome</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1920x1080</td>\n",
       "      <td>24-bit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>支持</td>\n",
       "      <td>支持</td>\n",
       "      <td>2019-02-22 13:42:29</td>\n",
       "      <td>14s</td>\n",
       "      <td>http://www.youkeda.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>187.0</td>\n",
       "      <td>2019/02/27 14:42:52</td>\n",
       "      <td>杭州</td>\n",
       "      <td>百度</td>\n",
       "      <td>https://www.bmatch.tech</td>\n",
       "      <td>bmatch</td>\n",
       "      <td>115.192.184.82</td>\n",
       "      <td>1885452069639056133</td>\n",
       "      <td>307s</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Google Chrome</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1680x1050</td>\n",
       "      <td>24-bit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>支持</td>\n",
       "      <td>不支持</td>\n",
       "      <td>2019-02-27 14:42:52</td>\n",
       "      <td>194s</td>\n",
       "      <td>https://www.bmatch.tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>906.0</td>\n",
       "      <td>2019/02/25 12:25:09</td>\n",
       "      <td>杭州</td>\n",
       "      <td>百度</td>\n",
       "      <td>https://www.bmatch.tech</td>\n",
       "      <td>b.match</td>\n",
       "      <td>112.17.240.209</td>\n",
       "      <td>2078682566481140752</td>\n",
       "      <td>15s</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Safari移动版</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32-bit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>支持</td>\n",
       "      <td>不支持</td>\n",
       "      <td>2019-02-25 12:25:09</td>\n",
       "      <td>12s</td>\n",
       "      <td>https://www.bmatch.tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1022.0</td>\n",
       "      <td>2019/02/22 21:19:22</td>\n",
       "      <td>杭州</td>\n",
       "      <td>百度</td>\n",
       "      <td>https://www.bmatch.tech</td>\n",
       "      <td>网易云课堂</td>\n",
       "      <td>60.186.223.214</td>\n",
       "      <td>1917635642669449575</td>\n",
       "      <td>38s</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Chrome移动版</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32-bit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>支持</td>\n",
       "      <td>不支持</td>\n",
       "      <td>2019-02-22 21:19:22</td>\n",
       "      <td>25s</td>\n",
       "      <td>https://www.bmatch.tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>186.0</td>\n",
       "      <td>2019/02/27 14:47:44</td>\n",
       "      <td>杭州</td>\n",
       "      <td>百度</td>\n",
       "      <td>https://www.bmatch.tech</td>\n",
       "      <td>bmatch</td>\n",
       "      <td>36.27.67.31</td>\n",
       "      <td>2294947012308152234</td>\n",
       "      <td>98s</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Google Chrome</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1680x1050</td>\n",
       "      <td>24-bit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>支持</td>\n",
       "      <td>不支持</td>\n",
       "      <td>2019-02-27 14:47:44</td>\n",
       "      <td>98s</td>\n",
       "      <td>https://www.bmatch.tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           visit_date domain ref_link              portal_page  \\\n",
       "0      1063.0  2019/02/22 13:42:29     深圳    360搜索   http://www.youkeda.com   \n",
       "1       187.0  2019/02/27 14:42:52     杭州       百度  https://www.bmatch.tech   \n",
       "2       906.0  2019/02/25 12:25:09     杭州       百度  https://www.bmatch.tech   \n",
       "3      1022.0  2019/02/22 21:19:22     杭州       百度  https://www.bmatch.tech   \n",
       "4       186.0  2019/02/27 14:47:44     杭州       百度  https://www.bmatch.tech   \n",
       "\n",
       "  keywords        visit_IP            unique_no total_visit_duration_time  \\\n",
       "0       --  219.133.66.223  1839110690557959428                       14s   \n",
       "1   bmatch  115.192.184.82  1885452069639056133                      307s   \n",
       "2  b.match  112.17.240.209  2078682566481140752                       15s   \n",
       "3    网易云课堂  60.186.223.214  1917635642669449575                       38s   \n",
       "4   bmatch     36.27.67.31  2294947012308152234                       98s   \n",
       "\n",
       "   total_visit_page_one_time           ...                    brewer lang  \\\n",
       "0                        1.0           ...             Google Chrome  NaN   \n",
       "1                        3.0           ...             Google Chrome  NaN   \n",
       "2                        3.0           ...                 Safari移动版  NaN   \n",
       "3                        3.0           ...                 Chrome移动版  NaN   \n",
       "4                        1.0           ...             Google Chrome  NaN   \n",
       "\n",
       "      screen  screen_color Flash has_cookie has_java  this_time_visit_start  \\\n",
       "0  1920x1080        24-bit   NaN         支持       支持    2019-02-22 13:42:29   \n",
       "1  1680x1050        24-bit   NaN         支持      不支持    2019-02-27 14:42:52   \n",
       "2        NaN        32-bit   NaN         支持      不支持    2019-02-25 12:25:09   \n",
       "3        NaN        32-bit   NaN         支持      不支持    2019-02-22 21:19:22   \n",
       "4  1680x1050        24-bit   NaN         支持      不支持    2019-02-27 14:47:44   \n",
       "\n",
       "  visit_portal_time               portal_url  \n",
       "0               14s   http://www.youkeda.com  \n",
       "1              194s  https://www.bmatch.tech  \n",
       "2               12s  https://www.bmatch.tech  \n",
       "3               25s  https://www.bmatch.tech  \n",
       "4               98s  https://www.bmatch.tech  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "archive_origin = pd.read_csv('ryf_source.csv', encoding = 'utf8')\n",
    "ad_df = archive_origin.copy()\n",
    "\n",
    "ad_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据清洗\n",
    "\n",
    "* 只分析来源是阮一峰广告的记录\n",
    "* 过滤掉公司IP\n",
    "* 两个停留时间进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#入口请求，阮一峰的页面\n",
    "ryf_url = 'https://www.bmatch.tech/course/react?from=ryf'\n",
    "buy_ad_url = 'http://www.ruanyifeng.com/support.html'\n",
    "tongji_url = 'https://tongji.baidu.com'\n",
    "#公司ip\n",
    "company_ip = '36.27.67.31'\n",
    "\n",
    "ad_df = ad_df[(ad_df['portal_page'] == ryf_url) & (ad_df['visit_IP'] != company_ip)]\n",
    "ad_df = ad_df[ad_df['ref_link'] != buy_ad_url]\n",
    "\n",
    "def time_str_to_second(str):\n",
    "    second = 0\n",
    "    if str[0].isdigit():\n",
    "        time_str = str[:-1]\n",
    "        second = int(time_str)\n",
    "    return second  \n",
    "\n",
    "def handle_str(row):\n",
    "    row['total_visit_duration_time'] = time_str_to_second(row['total_visit_duration_time'])\n",
    "    row['visit_portal_time'] = time_str_to_second(row['visit_portal_time'])\n",
    "\n",
    "    return row\n",
    "\n",
    "ad_df = ad_df.apply(handle_str, axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从URL中获取文章的标题和更新时间信息\n",
    "\n",
    "返回的数据结构如下： <br>\n",
    "`{\n",
    "   'title':'react',\n",
    "   'date':'2019/02'\n",
    "}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "def getTitle(url):\n",
    "    if url.startswith('http'):\n",
    "        urlobj = urlparse(url)\n",
    "        # 将url用“/”进行分割，同时去掉.html尾缀\n",
    "        str_list = urlobj.path.split('/')\n",
    "        if 'blog' in str_list:\n",
    "            seq = (str_list[2], str_list[3])\n",
    "            date = '@'.join(seq)\n",
    "            title = urlobj.path.split('/')[-1][:-5]\n",
    "            title = date + '@' + title\n",
    "            return title\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从文件夹中获取已经存在的文件名称的list\n",
    "import os\n",
    "html_file_dir = 'ryf_html'\n",
    "\n",
    "existed_files = []\n",
    "for file in os.listdir(html_file_dir):\n",
    "    if os.path.splitext(file)[1] == '.html':\n",
    "        existed_files.append(os.path.splitext(file)[0])\n",
    "\n",
    "#Index的nparray 转换成list\n",
    "all_blog_files = ad_df['ref_link'].map(getTitle).drop_duplicates().values.tolist()\n",
    "\n",
    "\n",
    "download_files = list(set(all_blog_files).difference(set(existed_files)))\n",
    "download_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download done\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "def filename2url(name):\n",
    "    url = \"\"\n",
    "    if name.strip() and name:\n",
    "        url = 'http://www.ruanyifeng.com/blog/' + name.replace(\"@\",\"/\") + '.html';\n",
    "    return url;\n",
    "\n",
    "def download_html(file):\n",
    "    url = filename2url(file)\n",
    "    if url.strip() and url:  \n",
    "        response = requests.get(url)\n",
    "        file_name = '@'.join(url.split('/')[-3:])\n",
    "        with open(os.path.join(html_file_dir, file_name), mode='wb') as file:\n",
    "            file.write(response.content)\n",
    "        return \n",
    "\n",
    "for name in download_files:\n",
    "    download_html(name)\n",
    "    \n",
    "print('download done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从文章的HTML结构中获取信息\n",
    "\n",
    "* 文章的类目从HTML结构中获取\n",
    "* 判断分类是否属于意向用户的范围（开发者手册，以及JavaScript偏向前端开发角色）<br>\n",
    "\n",
    "返回的数据结构如下：<br>\n",
    "`\n",
    "{\n",
    "  'intention': False/True,\n",
    "  'category':'JavaScript'\n",
    "}\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "good_category = ['开发者手册','JavaScript']\n",
    "\n",
    "def getCategory(url):\n",
    "    data = {'intention': False, 'category':''}\n",
    "\n",
    "    if 'www.' in url:\n",
    "        urlobj = urlparse(url)\n",
    "        file_name = '@'.join(urlobj.path.split('/')[-3:])\n",
    "        file_name = html_file_dir + '/' + file_name\n",
    "        with open(file_name, 'r') as f:\n",
    "            content = f.read()\n",
    "            soup = BeautifulSoup(content, 'lxml')\n",
    "            categorySpan = soup.find('div', {'class': 'entry-categories'})\n",
    "            if not categorySpan:\n",
    "                return data\n",
    "            category = categorySpan.find('a').string\n",
    "            if category in good_category:\n",
    "                data['intention'] = True\n",
    "            data['category'] = category\n",
    "            return data\n",
    "    return data\n",
    "\n",
    "def getTitleInfo(url):\n",
    "    if 'www.' in url:\n",
    "        urlobj = urlparse(url)\n",
    "        # 将url用“/”进行分割，同时去掉.html尾缀\n",
    "        str_list = urlobj.path.split('/')\n",
    "        if 'blog' in str_list:\n",
    "            seq = (str_list[2], str_list[3])\n",
    "            date = '/'.join(seq)\n",
    "            title = urlobj.path.split('/')[-1][:-5]\n",
    "            return {'title': title, 'date':date}\n",
    "    return {'title': '', 'date':''}\n",
    "\n",
    "\n",
    "# 得到处理后的文章标题，文章写作时间，是否是意向用户，以及文章的分类\n",
    "def analysis(url):\n",
    "    data = {'intention': False, \n",
    "            'category':'',\n",
    "            'title':'',\n",
    "            'article_written':'',\n",
    "            'ref_link':url}\n",
    "\n",
    "    \n",
    "    title_info = getTitleInfo(url)\n",
    "    data['article_written'] = title_info['date']\n",
    "    data['title'] = title_info['title']\n",
    "    html_info = getCategory(url)\n",
    "    data['category'] = html_info['category']\n",
    "    data['intention'] = html_info['intention']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "905                                                 直接访问\n",
      "962    http://www.ruanyifeng.com/blog/2006/02/post_17...\n",
      "Name: ref_link, dtype: object\n",
      "{'intention': False, 'category': '', 'title': '', 'article_written': '', 'ref_link': '直接访问'}\n",
      "{'intention': False, 'category': '观点与感想', 'title': 'post_179', 'article_written': '2006/02', 'ref_link': 'http://www.ruanyifeng.com/blog/2006/02/post_179.html'}\n"
     ]
    }
   ],
   "source": [
    "# 测试代码\n",
    "url_list = ad_df['ref_link'].drop_duplicates()[:2]\n",
    "print(url_list)\n",
    "for url in url_list:\n",
    "    data = analysis(url)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 得到处理后的数据表格，和原表格进行合并\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = ad_df['ref_link'].drop_duplicates()\n",
    "df_list = []\n",
    "\n",
    "for url in url_list :\n",
    "    data = analysis(url)\n",
    "    df_list.append(data)\n",
    "\n",
    "\n",
    "#将两个数据结构按照同一个key值进行合并\n",
    "new_df = pd.DataFrame(df_list, columns = ['ref_link', 'title', 'category', 'article_written', 'intention'])\n",
    "new_ad_df = pd.merge(ad_df, new_df, how='inner', on=['ref_link'])\n",
    "new_ad_df.head()\n",
    "\n",
    "#将得到的新表格，写入到本地文件\n",
    "new_ad_df.to_csv('handled_ryf_data.csv', index=False, encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
